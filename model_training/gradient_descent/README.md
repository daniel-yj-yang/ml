# Gradient Descent

<hr>

Approach | ---
--- | ---
<a href="batch_gradient_descent">Batch Gradient Descent</a> | ---
<a href="stochastic_gradient_descent">Stochastic Gradient Descent</a> (SGD) | It replaces the actual gradient (calculated from the entire data set) by an estimate **calculated from a randomly selected subset of the data**. Especially in high-dimensional optimization problems, this reduces the computational burden, achieving faster iterations in trade for a lower convergence rate.
