# Gradient Descent

<hr>

Approach | ---
--- | ---
<a href="batch_gradient_descent">Batch Gradient Descent</a> | ---
<a href="stochastic_gradient_descent">Stochastic Gradient Descent</a> (SGD) | Use a randomly selected subset of the data (rather than the entire data set) to estimate the gradient. Doing so helps reduce computational burden and achieve faster iterations, especially in high-dimension problems, although it may converge more slowly.
